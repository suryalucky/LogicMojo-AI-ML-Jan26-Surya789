{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 50 Homework Assignments - Python & Pandas for Machine Learning\n",
        "\n",
        "## üìö Overview\n",
        "\n",
        "This notebook contains **50 comprehensive homework assignments** covering:\n",
        "- **Part 1**: Python Data Structures (Tuples, Sets, Dictionaries) - 15 problems\n",
        "- **Part 2**: Python Functions & Functional Programming - 10 problems\n",
        "- **Part 3**: Pandas Basics & Data Manipulation - 15 problems\n",
        "- **Part 4**: Pandas Advanced Operations - 10 problems\n",
        "\n",
        "### üìä Difficulty Levels:\n",
        "- üü¢ **Easy**: Basic concepts, direct application\n",
        "- üü° **Medium**: Multiple concepts, some logic required\n",
        "- üî¥ **Hard**: Complex logic, multiple steps, real-world scenarios\n",
        "\n",
        "### üìù Instructions:\n",
        "1. Read each problem carefully\n",
        "2. Write your solution in the provided code cell\n",
        "3. Test your solution with the given examples\n",
        "4. Compare with the solution (hidden in collapsed cells)\n",
        "5. Try to solve without looking at solutions first!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Python Data Structures (15 Problems)\n",
        "\n",
        "## Section A: Tuples (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 1: Image Dimensions Handler üü¢\n",
        "\n",
        "**Topic**: Tuple unpacking and operations\n",
        "\n",
        "**Description**:\n",
        "You're working with image data in machine learning. Create a function that:\n",
        "1. Takes an image dimension tuple `(height, width, channels)`\n",
        "2. Returns a dictionary with keys: 'height', 'width', 'channels', 'total_pixels', 'is_grayscale'\n",
        "3. `total_pixels = height √ó width`\n",
        "4. `is_grayscale = True` if channels == 1, else False\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "image_info((224, 224, 3))\n",
        "# Output: {'height': 224, 'width': 224, 'channels': 3, 'total_pixels': 50176, 'is_grayscale': False}\n",
        "\n",
        "image_info((128, 128, 1))\n",
        "# Output: {'height': 128, 'width': 128, 'channels': 1, 'total_pixels': 16384, 'is_grayscale': True}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'widht': 224, 'height': 224, 'channels': 3, 'total_pixels': 50176, 'is_grayscale': False}\n",
            "{'widht': 128, 'height': 128, 'channels': 1, 'total_pixels': 16384, 'is_grayscale': True}\n"
          ]
        }
      ],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def image_info(dimensions):\n",
        "    width, height, channels = dimensions\n",
        "    return {\n",
        "        \"widht\": width,\n",
        "        \"height\": height,\n",
        "        \"channels\": channels,\n",
        "        \"total_pixels\": width * height,\n",
        "        \"is_grayscale\": channels == 1\n",
        "    }\n",
        "\n",
        "# Test your solution\n",
        "print(image_info((224, 224, 3)))\n",
        "print(image_info((128, 128, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 2: Coordinate Distance Calculator üü¢\n",
        "\n",
        "**Topic**: Tuple arithmetic and math operations\n",
        "\n",
        "**Description**:\n",
        "Calculate the Euclidean distance between two points in 2D space.\n",
        "- Formula: `distance = ‚àö((x2-x1)¬≤ + (y2-y1)¬≤)`\n",
        "- Input: Two tuples `(x, y)` representing coordinates\n",
        "- Output: Float (rounded to 2 decimal places)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "distance((0, 0), (3, 4))  # Output: 5.0\n",
        "distance((1, 2), (4, 6))  # Output: 5.0\n",
        "```\n",
        "\n",
        "**Hint**: Use `math.sqrt()` or `** 0.5` for square root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.0\n",
            "5.0\n"
          ]
        }
      ],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import math\n",
        "\n",
        "def distance(point1, point2):\n",
        "    return math.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
        "\n",
        "# Test your solution\n",
        "print(distance((0, 0), (3, 4)))\n",
        "print(distance((1, 2), (4, 6)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 3: Training Configuration Validator üü°\n",
        "\n",
        "**Topic**: Tuple immutability and validation\n",
        "\n",
        "**Description**:\n",
        "Create a function that validates ML training configurations stored as tuples:\n",
        "- Input: `(learning_rate, batch_size, epochs, optimizer)`\n",
        "- Validate:\n",
        "  - `learning_rate`: must be between 0.0001 and 1.0\n",
        "  - `batch_size`: must be power of 2 (16, 32, 64, 128, etc.)\n",
        "  - `epochs`: must be positive integer\n",
        "  - `optimizer`: must be one of ['adam', 'sgd', 'rmsprop']\n",
        "- Return: tuple `(is_valid, error_messages_list)`\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "validate_config((0.001, 32, 100, 'adam'))\n",
        "# Output: (True, [])\n",
        "\n",
        "validate_config((2.0, 30, -5, 'bad_optimizer'))\n",
        "# Output: (False, ['learning_rate out of range', 'batch_size not power of 2', 'epochs must be positive', 'invalid optimizer'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(True, [])\n",
            "(False, ['learning_rate must be between 0.0001 and 1.0', 'batch_size must be 16, 32, 64, 128, 256, or 512', 'epochs must be a positive integer', \"optimizer must be 'adam', 'sgd', or 'rmsprop'\"])\n"
          ]
        }
      ],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def validate_config(config):\n",
        "    learning_rate, batch_size, epochs, optimizer = config\n",
        "\n",
        "    Error = []\n",
        "\n",
        "    if learning_rate < 0.0001 or learning_rate > 1:\n",
        "         Error.append(\"learning_rate must be between 0.0001 and 1.0\")\n",
        "\n",
        "    if batch_size not in [16, 32, 64, 128, 256, 512]:\n",
        "        Error.append(\"batch_size must be 16, 32, 64, 128, 256, or 512\")\n",
        "\n",
        "    if not isinstance(epochs, int) or epochs <=0:\n",
        "        Error.append(\"epochs must be a positive integer\")\n",
        "\n",
        "    if optimizer.lower() not in ['adam', 'sgd', 'rmsprop']:\n",
        "        Error.append(\"optimizer must be 'adam', 'sgd', or 'rmsprop'\")\n",
        "\n",
        "    return len(Error) == 0, Error\n",
        "\n",
        "config = (2, 32, 2, 'adam')\n",
        "\n",
        "# Test your solution\n",
        "print(validate_config((0.001, 32, 100, 'adam')))\n",
        "print(validate_config((2.0, 30, -5, 'bad_optimizer')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 4: Data Split Generator üü°\n",
        "\n",
        "**Topic**: Tuple creation and list manipulation\n",
        "\n",
        "**Description**:\n",
        "Create a function that splits data indices for train/validation/test sets:\n",
        "- Input: `total_samples` (int), `train_ratio`, `val_ratio`, `test_ratio` (floats that sum to 1.0)\n",
        "- Output: Tuple of three ranges: `(train_indices, val_indices, test_indices)`\n",
        "- Each element should be a tuple of (start_index, end_index)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "split_data(100, 0.7, 0.2, 0.1)\n",
        "# Output: ((0, 70), (70, 90), (90, 100))\n",
        "\n",
        "split_data(1000, 0.8, 0.1, 0.1)\n",
        "# Output: ((0, 800), (800, 900), (900, 1000))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "((0, 69), (70, 89), (90, 99))\n",
            "((0, 799), (800, 899), (900, 999))\n"
          ]
        }
      ],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def split_data(total_samples, train_ratio, val_ratio, test_ratio):\n",
        "    train_end = int(total_samples * train_ratio)\n",
        "    val_end = train_end + int(total_samples * val_ratio)\n",
        "\n",
        "    train_indices = (0, train_end - 1)\n",
        "    val_indices = (train_end, val_end - 1)\n",
        "    test_indices = (val_end, total_samples - 1)\n",
        "\n",
        "    return train_indices, val_indices, test_indices\n",
        "\n",
        "# Test your solution\n",
        "print(split_data(100, 0.7, 0.2, 0.1))\n",
        "print(split_data(1000, 0.8, 0.1, 0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 5: Model Metrics Comparison üî¥\n",
        "\n",
        "**Topic**: Complex tuple operations and sorting\n",
        "\n",
        "**Description**:\n",
        "You have multiple ML models with their performance metrics as tuples:\n",
        "- Input: List of tuples `[(model_name, accuracy, precision, recall, f1_score), ...]`\n",
        "- Tasks:\n",
        "  1. Find the best model for each metric\n",
        "  2. Calculate average of all metrics across models\n",
        "  3. Return a dictionary with: `'best_models'`, `'averages'`, `'ranked_by_f1'`\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "models = [\n",
        "    ('Model_A', 0.85, 0.82, 0.88, 0.85),\n",
        "    ('Model_B', 0.92, 0.90, 0.85, 0.87),\n",
        "    ('Model_C', 0.88, 0.85, 0.92, 0.88)\n",
        "]\n",
        "\n",
        "compare_models(models)\n",
        "# Output: {\n",
        "#     'best_models': {\n",
        "#         'accuracy': 'Model_B',\n",
        "#         'precision': 'Model_B',\n",
        "#         'recall': 'Model_C',\n",
        "#         'f1_score': 'Model_C'\n",
        "#     },\n",
        "#     'averages': {'accuracy': 0.88, 'precision': 0.86, 'recall': 0.88, 'f1_score': 0.87},\n",
        "#     'ranked_by_f1': ['Model_C', 'Model_B', 'Model_A']\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def compare_models(models):\n",
        "    metrics_index = [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
        "\n",
        "    #Best model\n",
        "    best_model = {}\n",
        "    for metric in metrics_index:\n",
        "        index = metrics_index[metric]\n",
        "        best_name = \"\"\n",
        "        best_value = 0\n",
        "\n",
        "        for model in models:\n",
        "            if model[index] > best_value:\n",
        "                best_value = model[index]\n",
        "                best_name = model[0]\n",
        "\n",
        "        best_model[metric] = best_name   \n",
        "\n",
        "    #Average\n",
        "    #          \n",
        "\n",
        "# Test your solution\n",
        "models = [\n",
        "    ('Model_A', 0.85, 0.82, 0.88, 0.85),\n",
        "    ('Model_B', 0.92, 0.90, 0.85, 0.87),\n",
        "    ('Model_C', 0.88, 0.85, 0.92, 0.88)\n",
        "]\n",
        "print(compare_models(models))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section B: Sets (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 6: Duplicate Detector üü¢\n",
        "\n",
        "**Topic**: Set basics and uniqueness\n",
        "\n",
        "**Description**:\n",
        "Find duplicate values in a list and return statistics:\n",
        "- Input: List of any values\n",
        "- Output: Dictionary with:\n",
        "  - `'has_duplicates'`: Boolean\n",
        "  - `'unique_count'`: Number of unique values\n",
        "  - `'duplicate_count'`: Number of duplicate values\n",
        "  - `'duplicates'`: Set of duplicate values\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "find_duplicates([1, 2, 3, 2, 4, 3, 5])\n",
        "# Output: {'has_duplicates': True, 'unique_count': 5, 'duplicate_count': 2, 'duplicates': {2, 3}}\n",
        "\n",
        "find_duplicates([1, 2, 3, 4, 5])\n",
        "# Output: {'has_duplicates': False, 'unique_count': 5, 'duplicate_count': 0, 'duplicates': set()}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def find_duplicates(data):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "print(find_duplicates([1, 2, 3, 2, 4, 3, 5]))\n",
        "print(find_duplicates([1, 2, 3, 4, 5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 7: Feature Engineering - Categorical Encoder üü°\n",
        "\n",
        "**Topic**: Set operations for ML preprocessing\n",
        "\n",
        "**Description**:\n",
        "Create a simple categorical encoder:\n",
        "- Input: List of categorical values (strings)\n",
        "- Output: Dictionary with:\n",
        "  - `'encoding_map'`: Dictionary mapping each unique category to an integer (0, 1, 2, ...)\n",
        "  - `'encoded_data'`: List of encoded integers\n",
        "  - `'num_categories'`: Number of unique categories\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "encode_categories(['cat', 'dog', 'cat', 'bird', 'dog', 'cat'])\n",
        "# Output: {\n",
        "#     'encoding_map': {'cat': 0, 'dog': 1, 'bird': 2},\n",
        "#     'encoded_data': [0, 1, 0, 2, 1, 0],\n",
        "#     'num_categories': 3\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def encode_categories(data):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "print(encode_categories(['cat', 'dog', 'cat', 'bird', 'dog', 'cat']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 8: Dataset Overlap Analyzer üü°\n",
        "\n",
        "**Topic**: Set operations (union, intersection, difference)\n",
        "\n",
        "**Description**:\n",
        "Analyze overlap between training and test datasets:\n",
        "- Input: Two lists (train_ids, test_ids)\n",
        "- Output: Dictionary with:\n",
        "  - `'total_unique'`: Total unique IDs across both sets\n",
        "  - `'overlap'`: IDs present in both sets (data leakage!)\n",
        "  - `'only_train'`: IDs only in training\n",
        "  - `'only_test'`: IDs only in test\n",
        "  - `'has_leakage'`: Boolean (True if overlap exists)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "analyze_overlap([1, 2, 3, 4, 5], [4, 5, 6, 7, 8])\n",
        "# Output: {\n",
        "#     'total_unique': 8,\n",
        "#     'overlap': {4, 5},\n",
        "#     'only_train': {1, 2, 3},\n",
        "#     'only_test': {6, 7, 8},\n",
        "#     'has_leakage': True\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def analyze_overlap(train_ids, test_ids):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "print(analyze_overlap([1, 2, 3, 4, 5], [4, 5, 6, 7, 8]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 9: Text Preprocessing - Stopword Remover üü°\n",
        "\n",
        "**Topic**: Set operations for text processing\n",
        "\n",
        "**Description**:\n",
        "Remove stopwords from text using sets:\n",
        "- Input: Text string and set of stopwords\n",
        "- Output: Dictionary with:\n",
        "  - `'original_words'`: List of all words\n",
        "  - `'filtered_words'`: List of words after removing stopwords\n",
        "  - `'removed_count'`: Number of words removed\n",
        "  - `'unique_filtered'`: Set of unique words after filtering\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "stopwords = {'the', 'is', 'a', 'an', 'in', 'on', 'at'}\n",
        "text = \"the cat is on the mat in the house\"\n",
        "\n",
        "remove_stopwords(text, stopwords)\n",
        "# Output: {\n",
        "#     'original_words': ['the', 'cat', 'is', 'on', 'the', 'mat', 'in', 'the', 'house'],\n",
        "#     'filtered_words': ['cat', 'mat', 'house'],\n",
        "#     'removed_count': 6,\n",
        "#     'unique_filtered': {'cat', 'mat', 'house'}\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def remove_stopwords(text, stopwords):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "stopwords = {'the', 'is', 'a', 'an', 'in', 'on', 'at'}\n",
        "text = \"the cat is on the mat in the house\"\n",
        "print(remove_stopwords(text, stopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 10: Feature Selection - Correlation Filter üî¥\n",
        "\n",
        "**Topic**: Advanced set operations\n",
        "\n",
        "**Description**:\n",
        "Filter highly correlated feature pairs:\n",
        "- Input: Dictionary of feature pairs and their correlation: `{('f1', 'f2'): 0.95, ...}`\n",
        "- Threshold: Correlation threshold (e.g., 0.9)\n",
        "- Output: Dictionary with:\n",
        "  - `'highly_correlated_pairs'`: Set of feature pairs above threshold\n",
        "  - `'features_to_remove'`: Set of features to remove (keep only one from each pair)\n",
        "  - `'features_to_keep'`: Set of features to keep\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "correlations = {\n",
        "    ('f1', 'f2'): 0.95,\n",
        "    ('f1', 'f3'): 0.5,\n",
        "    ('f2', 'f4'): 0.92,\n",
        "    ('f3', 'f4'): 0.3\n",
        "}\n",
        "\n",
        "filter_correlated(correlations, threshold=0.9)\n",
        "# Output: {\n",
        "#     'highly_correlated_pairs': {('f1', 'f2'), ('f2', 'f4')},\n",
        "#     'features_to_remove': {'f2'},  # f2 appears in both correlated pairs\n",
        "#     'features_to_keep': {'f1', 'f3', 'f4'}\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def filter_correlated(correlations, threshold):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "correlations = {\n",
        "    ('f1', 'f2'): 0.95,\n",
        "    ('f1', 'f3'): 0.5,\n",
        "    ('f2', 'f4'): 0.92,\n",
        "    ('f3', 'f4'): 0.3\n",
        "}\n",
        "print(filter_correlated(correlations, threshold=0.9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section C: Dictionaries (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 11: Hyperparameter Grid Search üü¢\n",
        "\n",
        "**Topic**: Dictionary basics and nested structures\n",
        "\n",
        "**Description**:\n",
        "Generate all combinations of hyperparameters for grid search:\n",
        "- Input: Dictionary where keys are parameter names and values are lists of options\n",
        "- Output: List of dictionaries, each representing one parameter combination\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "params = {\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'batch_size': [32, 64],\n",
        "    'epochs': [10, 20]\n",
        "}\n",
        "\n",
        "generate_grid(params)\n",
        "# Output: [\n",
        "#     {'learning_rate': 0.01, 'batch_size': 32, 'epochs': 10},\n",
        "#     {'learning_rate': 0.01, 'batch_size': 32, 'epochs': 20},\n",
        "#     {'learning_rate': 0.01, 'batch_size': 64, 'epochs': 10},\n",
        "#     ... (8 combinations total)\n",
        "# ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "from itertools import product\n",
        "\n",
        "def generate_grid(params):\n",
        "    # Write your code here\n",
        "    # Hint: Use itertools.product for Cartesian product\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "params = {\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'batch_size': [32, 64],\n",
        "    'epochs': [10, 20]\n",
        "}\n",
        "result = generate_grid(params)\n",
        "print(f\"Total combinations: {len(result)}\")\n",
        "print(\"First 3:\", result[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 12: Feature Statistics Calculator üü°\n",
        "\n",
        "**Topic**: Dictionary operations and statistics\n",
        "\n",
        "**Description**:\n",
        "Calculate statistics for each feature in a dataset:\n",
        "- Input: Dictionary where keys are feature names and values are lists of numbers\n",
        "- Output: Dictionary with nested statistics for each feature:\n",
        "  - 'mean', 'median', 'std', 'min', 'max', 'q1', 'q3'\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "data = {\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'income': [50000, 60000, 70000, 80000, 90000]\n",
        "}\n",
        "\n",
        "calculate_stats(data)\n",
        "# Output: {\n",
        "#     'age': {'mean': 35.0, 'median': 35.0, 'std': 7.07, 'min': 25, 'max': 45, 'q1': 30.0, 'q3': 40.0},\n",
        "#     'income': {'mean': 70000.0, 'median': 70000.0, 'std': 14142.14, 'min': 50000, 'max': 90000, 'q1': 60000.0, 'q3': 80000.0}\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import statistics\n",
        "\n",
        "def calculate_stats(data):\n",
        "    # Write your code here\n",
        "    # Hint: Use statistics module (mean, median, stdev) and sorted() for quartiles\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "data = {\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'income': [50000, 60000, 70000, 80000, 90000]\n",
        "}\n",
        "print(calculate_stats(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 13: Data Aggregator üü°\n",
        "\n",
        "**Topic**: Dictionary aggregation and grouping\n",
        "\n",
        "**Description**:\n",
        "Group and aggregate data by category:\n",
        "- Input: List of dictionaries, each with 'category' and 'value' keys\n",
        "- Output: Dictionary where:\n",
        "  - Keys are categories\n",
        "  - Values are dictionaries with: 'count', 'sum', 'avg', 'values_list'\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "data = [\n",
        "    {'category': 'A', 'value': 10},\n",
        "    {'category': 'B', 'value': 20},\n",
        "    {'category': 'A', 'value': 15},\n",
        "    {'category': 'B', 'value': 25},\n",
        "    {'category': 'A', 'value': 12}\n",
        "]\n",
        "\n",
        "aggregate_data(data)\n",
        "# Output: {\n",
        "#     'A': {'count': 3, 'sum': 37, 'avg': 12.33, 'values_list': [10, 15, 12]},\n",
        "#     'B': {'count': 2, 'sum': 45, 'avg': 22.5, 'values_list': [20, 25]}\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def aggregate_data(data):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "data = [\n",
        "    {'category': 'A', 'value': 10},\n",
        "    {'category': 'B', 'value': 20},\n",
        "    {'category': 'A', 'value': 15},\n",
        "    {'category': 'B', 'value': 25},\n",
        "    {'category': 'A', 'value': 12}\n",
        "]\n",
        "print(aggregate_data(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 14: Confusion Matrix Builder üî¥\n",
        "\n",
        "**Topic**: Nested dictionaries and ML metrics\n",
        "\n",
        "**Description**:\n",
        "Build a confusion matrix from predictions and actual values:\n",
        "- Input: Two lists (actual, predicted) of same length\n",
        "- Output: Dictionary with:\n",
        "  - `'matrix'`: Nested dict {actual: {predicted: count}}\n",
        "  - `'accuracy'`: Overall accuracy\n",
        "  - `'per_class'`: Dict with precision, recall, f1 for each class\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "actual = ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C']\n",
        "predicted = ['A', 'B', 'B', 'C', 'A', 'A', 'C', 'B']\n",
        "\n",
        "build_confusion_matrix(actual, predicted)\n",
        "# Output: {\n",
        "#     'matrix': {\n",
        "#         'A': {'A': 2, 'B': 1},\n",
        "#         'B': {'B': 1, 'A': 1},\n",
        "#         'C': {'C': 2, 'B': 1}\n",
        "#     },\n",
        "#     'accuracy': 0.625,  # 5 correct out of 8\n",
        "#     'per_class': {\n",
        "#         'A': {'precision': 0.5, 'recall': 0.67, 'f1': 0.57},\n",
        "#         'B': {'precision': 0.33, 'recall': 0.5, 'f1': 0.4},\n",
        "#         'C': {'precision': 1.0, 'recall': 0.67, 'f1': 0.8}\n",
        "#     }\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def build_confusion_matrix(actual, predicted):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "actual = ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C']\n",
        "predicted = ['A', 'B', 'B', 'C', 'A', 'A', 'C', 'B']\n",
        "print(build_confusion_matrix(actual, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 15: Configuration Merger üî¥\n",
        "\n",
        "**Topic**: Nested dictionary operations\n",
        "\n",
        "**Description**:\n",
        "Merge multiple configuration dictionaries with priority rules:\n",
        "- Input: List of config dicts (later configs override earlier ones)\n",
        "- Handle nested dictionaries (deep merge)\n",
        "- Output: Single merged configuration\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "configs = [\n",
        "    {'model': {'layers': 3, 'dropout': 0.5}, 'lr': 0.01},\n",
        "    {'model': {'layers': 5}, 'batch_size': 32},\n",
        "    {'model': {'dropout': 0.3}, 'lr': 0.001}\n",
        "]\n",
        "\n",
        "merge_configs(configs)\n",
        "# Output: {\n",
        "#     'model': {'layers': 5, 'dropout': 0.3},\n",
        "#     'lr': 0.001,\n",
        "#     'batch_size': 32\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def merge_configs(configs):\n",
        "    # Write your code here\n",
        "    # Hint: Use recursive approach for nested dicts\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "configs = [\n",
        "    {'model': {'layers': 3, 'dropout': 0.5}, 'lr': 0.01},\n",
        "    {'model': {'layers': 5}, 'batch_size': 32},\n",
        "    {'model': {'dropout': 0.3}, 'lr': 0.001}\n",
        "]\n",
        "print(merge_configs(configs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Python Functions & Functional Programming (10 Problems)\n",
        "\n",
        "## Section D: Functions (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 16: Decorator - Execution Timer üü°\n",
        "\n",
        "**Topic**: Function decorators\n",
        "\n",
        "**Description**:\n",
        "Create a decorator that measures function execution time:\n",
        "- Decorator should print: function name, execution time in milliseconds\n",
        "- Should work with any function\n",
        "- Return the original function's result\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "@timer\n",
        "def slow_function(n):\n",
        "    time.sleep(n)\n",
        "    return n * 2\n",
        "\n",
        "result = slow_function(0.5)\n",
        "# Output: \"slow_function executed in 500.23 ms\"\n",
        "# result = 1.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import time\n",
        "\n",
        "def timer(func):\n",
        "    # Write your decorator here\n",
        "    pass\n",
        "\n",
        "# Test your decorator\n",
        "@timer\n",
        "def slow_function(n):\n",
        "    time.sleep(n)\n",
        "    return n * 2\n",
        "\n",
        "result = slow_function(0.5)\n",
        "print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 17: Memoization Cache üî¥\n",
        "\n",
        "**Topic**: Closures and caching\n",
        "\n",
        "**Description**:\n",
        "Create a memoization decorator for expensive functions:\n",
        "- Cache function results based on arguments\n",
        "- Return cached result if same arguments are used again\n",
        "- Track cache hits and misses\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "@memoize\n",
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "print(fibonacci(10))  # Computes and caches\n",
        "print(fibonacci(10))  # Returns from cache\n",
        "print(fibonacci.cache_info())  # {'hits': 1, 'misses': 11, 'size': 11}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def memoize(func):\n",
        "    # Write your memoization decorator here\n",
        "    pass\n",
        "\n",
        "# Test your decorator\n",
        "@memoize\n",
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "print(\"First call:\", fibonacci(10))\n",
        "print(\"Second call:\", fibonacci(10))\n",
        "print(\"Cache info:\", fibonacci.cache_info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 18: Partial Function Application üü°\n",
        "\n",
        "**Topic**: Closures and function factories\n",
        "\n",
        "**Description**:\n",
        "Create a function factory for ML model evaluators:\n",
        "- Input: Metric name ('accuracy', 'precision', 'recall', 'f1')\n",
        "- Output: Function that calculates that metric given y_true and y_pred\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "accuracy_fn = create_metric('accuracy')\n",
        "precision_fn = create_metric('precision')\n",
        "\n",
        "y_true = [1, 0, 1, 1, 0]\n",
        "y_pred = [1, 0, 1, 0, 0]\n",
        "\n",
        "print(accuracy_fn(y_true, y_pred))  # 0.8 (4/5 correct)\n",
        "print(precision_fn(y_true, y_pred))  # 1.0 (all predicted 1s are correct)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def create_metric(metric_name):\n",
        "    # Write your function factory here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "accuracy_fn = create_metric('accuracy')\n",
        "precision_fn = create_metric('precision')\n",
        "\n",
        "y_true = [1, 0, 1, 1, 0]\n",
        "y_pred = [1, 0, 1, 0, 0]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_fn(y_true, y_pred))\n",
        "print(\"Precision:\", precision_fn(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 19: Pipeline Builder üî¥\n",
        "\n",
        "**Topic**: Function composition and *args\n",
        "\n",
        "**Description**:\n",
        "Create a pipeline that applies multiple functions in sequence:\n",
        "- Input: Variable number of functions\n",
        "- Output: Single function that applies all functions in order\n",
        "- Data flows from left to right\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "def normalize(x):\n",
        "    return [i / max(x) for i in x]\n",
        "\n",
        "def square(x):\n",
        "    return [i ** 2 for i in x]\n",
        "\n",
        "def sum_all(x):\n",
        "    return sum(x)\n",
        "\n",
        "pipeline = create_pipeline(normalize, square, sum_all)\n",
        "result = pipeline([1, 2, 3, 4, 5])\n",
        "# normalize: [0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "# square: [0.04, 0.16, 0.36, 0.64, 1.0]\n",
        "# sum_all: 2.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def create_pipeline(*functions):\n",
        "    # Write your pipeline builder here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "def normalize(x):\n",
        "    return [i / max(x) for i in x]\n",
        "\n",
        "def square(x):\n",
        "    return [i ** 2 for i in x]\n",
        "\n",
        "def sum_all(x):\n",
        "    return sum(x)\n",
        "\n",
        "pipeline = create_pipeline(normalize, square, sum_all)\n",
        "result = pipeline([1, 2, 3, 4, 5])\n",
        "print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 20: Currying üî¥\n",
        "\n",
        "**Topic**: Currying and partial application\n",
        "\n",
        "**Description**:\n",
        "Transform a function that takes multiple arguments into a sequence of functions each taking a single argument:\n",
        "- Input: Function with N parameters\n",
        "- Output: Curried version that can be called step by step\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "def add_three(a, b, c):\n",
        "    return a + b + c\n",
        "\n",
        "curried_add = curry(add_three)\n",
        "result = curried_add(1)(2)(3)  # 6\n",
        "\n",
        "# Or partial application\n",
        "add_1 = curried_add(1)\n",
        "add_1_2 = add_1(2)\n",
        "result = add_1_2(3)  # 6\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def curry(func):\n",
        "    # Write your currying function here\n",
        "    # Hint: Use inspect.signature to get function arity\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "def add_three(a, b, c):\n",
        "    return a + b + c\n",
        "\n",
        "curried_add = curry(add_three)\n",
        "result1 = curried_add(1)(2)(3)\n",
        "print(f\"Curried: {result1}\")\n",
        "\n",
        "add_1 = curried_add(1)\n",
        "add_1_2 = add_1(2)\n",
        "result2 = add_1_2(3)\n",
        "print(f\"Partial application: {result2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section E: Functional Programming (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 21: Data Transformation Pipeline üü¢\n",
        "\n",
        "**Topic**: map, filter, lambda\n",
        "\n",
        "**Description**:\n",
        "Transform raw data using functional programming:\n",
        "- Input: List of strings representing numbers: `['1', '2', '3', '4', '5', '6']`\n",
        "- Tasks:\n",
        "  1. Convert to integers\n",
        "  2. Filter even numbers only\n",
        "  3. Square each number\n",
        "  4. Return sum\n",
        "- Use map, filter, lambda (no loops!)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "transform_data(['1', '2', '3', '4', '5', '6'])\n",
        "# Steps: ['1','2','3','4','5','6'] -> [1,2,3,4,5,6] -> [2,4,6] -> [4,16,36] -> 56\n",
        "# Output: 56\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def transform_data(data):\n",
        "    # Write your solution using map, filter, lambda\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "result = transform_data(['1', '2', '3', '4', '5', '6'])\n",
        "print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 22: Feature Scaler üü°\n",
        "\n",
        "**Topic**: Lambda and list comprehensions\n",
        "\n",
        "**Description**:\n",
        "Create different scaling functions using lambdas:\n",
        "- Min-Max scaling: `(x - min) / (max - min)`\n",
        "- Z-score normalization: `(x - mean) / std`\n",
        "- Robust scaling: `(x - median) / IQR`\n",
        "- Input: List of numbers and scaling type\n",
        "- Output: Scaled list\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "data = [1, 2, 3, 4, 5]\n",
        "\n",
        "scale_features(data, 'minmax')\n",
        "# Output: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "scale_features(data, 'zscore')\n",
        "# Output: [-1.41, -0.71, 0.0, 0.71, 1.41]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import statistics\n",
        "\n",
        "def scale_features(data, method):\n",
        "    # Write your scaling function here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "data = [1, 2, 3, 4, 5]\n",
        "print(\"Min-Max:\", scale_features(data, 'minmax'))\n",
        "print(\"Z-score:\", scale_features(data, 'zscore'))\n",
        "print(\"Robust:\", scale_features(data, 'robust'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 23: reduce() - Custom Aggregations üü°\n",
        "\n",
        "**Topic**: reduce() for complex aggregations\n",
        "\n",
        "**Description**:\n",
        "Use `reduce()` to implement custom aggregation functions:\n",
        "1. Product of all elements\n",
        "2. Maximum value\n",
        "3. Concatenate strings with separator\n",
        "4. Flatten nested lists\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "product([1, 2, 3, 4, 5])  # 120\n",
        "maximum([3, 1, 4, 1, 5, 9, 2, 6])  # 9\n",
        "join_strings(['Hello', 'World', 'ML'], ' ')  # 'Hello World ML'\n",
        "flatten([[1, 2], [3, 4], [5, 6]])  # [1, 2, 3, 4, 5, 6]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "from functools import reduce\n",
        "\n",
        "def product(numbers):\n",
        "    # Write using reduce\n",
        "    pass\n",
        "\n",
        "def maximum(numbers):\n",
        "    # Write using reduce\n",
        "    pass\n",
        "\n",
        "def join_strings(strings, separator):\n",
        "    # Write using reduce\n",
        "    pass\n",
        "\n",
        "def flatten(nested_list):\n",
        "    # Write using reduce\n",
        "    pass\n",
        "\n",
        "# Test your solutions\n",
        "print(\"Product:\", product([1, 2, 3, 4, 5]))\n",
        "print(\"Maximum:\", maximum([3, 1, 4, 1, 5, 9, 2, 6]))\n",
        "print(\"Join:\", join_strings(['Hello', 'World', 'ML'], ' '))\n",
        "print(\"Flatten:\", flatten([[1, 2], [3, 4], [5, 6]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 24: Comprehension Olympics üî¥\n",
        "\n",
        "**Topic**: Nested comprehensions and conditional logic\n",
        "\n",
        "**Description**:\n",
        "Solve these using comprehensions (no loops!):\n",
        "\n",
        "1. **Matrix Transpose**: Transpose a 2D matrix\n",
        "2. **Flatten with Condition**: Flatten matrix but only include even numbers\n",
        "3. **Cartesian Product**: All pairs from two lists where sum > 5\n",
        "4. **Dict Inversion**: Invert dict (values become keys), handle duplicates\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "transpose(matrix)  # [[1, 4, 7], [2, 5, 8], [3, 6, 9]]\n",
        "\n",
        "flatten_even(matrix)  # [2, 4, 6, 8]\n",
        "\n",
        "cartesian([1, 2, 3], [4, 5, 6])  # [(2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6)]\n",
        "\n",
        "invert_dict({'a': 1, 'b': 2, 'c': 1})  # {1: ['a', 'c'], 2: ['b']}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def transpose(matrix):\n",
        "    # Write using list comprehension\n",
        "    pass\n",
        "\n",
        "def flatten_even(matrix):\n",
        "    # Write using list comprehension\n",
        "    pass\n",
        "\n",
        "def cartesian(list1, list2, threshold=5):\n",
        "    # Write using list comprehension\n",
        "    pass\n",
        "\n",
        "def invert_dict(d):\n",
        "    # Write using dict comprehension\n",
        "    pass\n",
        "\n",
        "# Test your solutions\n",
        "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "print(\"Transpose:\", transpose(matrix))\n",
        "print(\"Flatten even:\", flatten_even(matrix))\n",
        "print(\"Cartesian:\", cartesian([1, 2, 3], [4, 5, 6]))\n",
        "print(\"Invert:\", invert_dict({'a': 1, 'b': 2, 'c': 1}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 25: Function Combinator üî¥\n",
        "\n",
        "**Topic**: Higher-order functions\n",
        "\n",
        "**Description**:\n",
        "Create function combinators:\n",
        "1. `compose`: Combine functions right-to-left: `compose(f, g, h)(x)` = `f(g(h(x)))`\n",
        "2. `pipe`: Combine functions left-to-right: `pipe(f, g, h)(x)` = `h(g(f(x)))`\n",
        "3. `parallel`: Apply multiple functions and collect results: `parallel(f, g)(x)` = `[f(x), g(x)]`\n",
        "4. `conditional`: Apply function based on predicate: `conditional(pred, f, g)(x)` = `f(x) if pred(x) else g(x)`\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "add_2 = lambda x: x + 2\n",
        "mult_3 = lambda x: x * 3\n",
        "square = lambda x: x ** 2\n",
        "\n",
        "compose(square, mult_3, add_2)(5)  # square(mult_3(add_2(5))) = square(21) = 441\n",
        "pipe(add_2, mult_3, square)(5)  # square(mult_3(add_2(5))) = square(21) = 441\n",
        "parallel(add_2, mult_3, square)(5)  # [7, 15, 25]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "def compose(*functions):\n",
        "    # Write composer (right-to-left)\n",
        "    pass\n",
        "\n",
        "def pipe(*functions):\n",
        "    # Write pipe (left-to-right)\n",
        "    pass\n",
        "\n",
        "def parallel(*functions):\n",
        "    # Write parallel applicator\n",
        "    pass\n",
        "\n",
        "def conditional(predicate, true_func, false_func):\n",
        "    # Write conditional applicator\n",
        "    pass\n",
        "\n",
        "# Test your solutions\n",
        "add_2 = lambda x: x + 2\n",
        "mult_3 = lambda x: x * 3\n",
        "square = lambda x: x ** 2\n",
        "\n",
        "print(\"Compose:\", compose(square, mult_3, add_2)(5))\n",
        "print(\"Pipe:\", pipe(add_2, mult_3, square)(5))\n",
        "print(\"Parallel:\", parallel(add_2, mult_3, square)(5))\n",
        "print(\"Conditional:\", conditional(lambda x: x > 0, add_2, mult_3)(5))\n",
        "print(\"Conditional:\", conditional(lambda x: x > 0, add_2, mult_3)(-5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3: Pandas Basics & Data Manipulation (15 Problems)\n",
        "\n",
        "## Section F: Series & DataFrames (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 26: Series Statistics Calculator üü¢\n",
        "\n",
        "**Topic**: Series creation and basic operations\n",
        "\n",
        "**Description**:\n",
        "Create a Pandas Series from a list and calculate comprehensive statistics:\n",
        "- Input: List of numbers\n",
        "- Output: Dictionary with: mean, median, std, var, min, max, q1, q3, skew\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "series_stats([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "# Output: {'mean': 5.5, 'median': 5.5, 'std': 3.03, 'var': 9.17, 'min': 1.0, 'max': 10.0, 'q1': 3.25, 'q3': 7.75, 'skew': 0.0}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def series_stats(data):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "result = series_stats([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 27: DataFrame from Multiple Sources üü¢\n",
        "\n",
        "**Topic**: DataFrame creation from different data structures\n",
        "\n",
        "**Description**:\n",
        "Create a function that builds a DataFrame from multiple input formats:\n",
        "- Dictionary of lists\n",
        "- List of dictionaries\n",
        "- List of tuples with column names\n",
        "- Dictionary of Series\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# From dict of lists\n",
        "create_dataframe({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "\n",
        "# From list of dicts\n",
        "create_dataframe([{'A': 1, 'B': 4}, {'A': 2, 'B': 5}, {'A': 3, 'B': 6}])\n",
        "\n",
        "# Both produce:\n",
        "#    A  B\n",
        "# 0  1  4\n",
        "# 1  2  5\n",
        "# 2  3  6\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def create_dataframe(data, columns=None):\n",
        "    # Write your code here\n",
        "    # Handle different input types\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "print(\"Method 1: Dict of lists\")\n",
        "print(create_dataframe({'A': [1, 2, 3], 'B': [4, 5, 6]}))\n",
        "\n",
        "print(\"\\nMethod 2: List of dicts\")\n",
        "print(create_dataframe([{'A': 1, 'B': 4}, {'A': 2, 'B': 5}, {'A': 3, 'B': 6}]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 28: Custom Index Creator üü°\n",
        "\n",
        "**Topic**: DataFrame indexing and custom indices\n",
        "\n",
        "**Description**:\n",
        "Create a DataFrame with custom index based on requirements:\n",
        "- Input: Data and index type ('numeric', 'date', 'custom')\n",
        "- For 'numeric': Start from 100, step by 5\n",
        "- For 'date': Daily dates from '2024-01-01'\n",
        "- For 'custom': Use provided list as index\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "data = {'Score': [85, 90, 78, 92, 88]}\n",
        "\n",
        "create_with_index(data, 'numeric')\n",
        "# Index: [100, 105, 110, 115, 120]\n",
        "\n",
        "create_with_index(data, 'date')\n",
        "# Index: DatetimeIndex(['2024-01-01', '2024-01-02', ...])\n",
        "\n",
        "create_with_index(data, 'custom', custom_index=['A', 'B', 'C', 'D', 'E'])\n",
        "# Index: ['A', 'B', 'C', 'D', 'E']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def create_with_index(data, index_type, custom_index=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "data = {'Score': [85, 90, 78, 92, 88]}\n",
        "\n",
        "print(\"Numeric index:\")\n",
        "print(create_with_index(data, 'numeric'))\n",
        "\n",
        "print(\"\\nDate index:\")\n",
        "print(create_with_index(data, 'date'))\n",
        "\n",
        "print(\"\\nCustom index:\")\n",
        "print(create_with_index(data, 'custom', custom_index=['A', 'B', 'C', 'D', 'E']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 29: DataFrame Info Extractor üü°\n",
        "\n",
        "**Topic**: DataFrame inspection and metadata\n",
        "\n",
        "**Description**:\n",
        "Extract comprehensive information about a DataFrame:\n",
        "- Shape, column names, dtypes, memory usage\n",
        "- Missing values count per column\n",
        "- Unique values count per column\n",
        "- Basic statistics for numeric columns\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'Age': [25, 30, None, 35, 40],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Salary': [50000, 60000, 70000, None, 90000]\n",
        "})\n",
        "\n",
        "extract_info(df)\n",
        "# Output: {\n",
        "#     'shape': (5, 3),\n",
        "#     'columns': ['Age', 'Name', 'Salary'],\n",
        "#     'dtypes': {'Age': 'float64', 'Name': 'object', 'Salary': 'float64'},\n",
        "#     'missing_values': {'Age': 1, 'Name': 0, 'Salary': 1},\n",
        "#     'unique_counts': {'Age': 4, 'Name': 5, 'Salary': 4},\n",
        "#     'memory_mb': 0.00024,\n",
        "#     'numeric_summary': {...}\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def extract_info(df):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'Age': [25, 30, None, 35, 40],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Salary': [50000, 60000, 70000, None, 90000]\n",
        "})\n",
        "\n",
        "info = extract_info(df)\n",
        "print(\"DataFrame Info:\")\n",
        "for key, value in info.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 30: Row and Column Analyzer üî¥\n",
        "\n",
        "**Topic**: Advanced DataFrame operations\n",
        "\n",
        "**Description**:\n",
        "Analyze rows and columns of a DataFrame:\n",
        "- Find rows with any/all missing values\n",
        "- Find columns with >50% missing data\n",
        "- Identify duplicate rows\n",
        "- Find numeric columns that are highly correlated (>0.9)\n",
        "- Return detailed analysis dictionary\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, None, 4, 5],\n",
        "    'B': [None, None, None, None, 5],\n",
        "    'C': [1, 2, 3, 4, 5],\n",
        "    'D': [1.1, 2.1, 3.1, 4.1, 5.1]  # Highly correlated with C\n",
        "})\n",
        "\n",
        "analyze_dataframe(df)\n",
        "# Output: {\n",
        "#     'rows_with_missing': [0, 1, 2, 3],\n",
        "#     'rows_all_missing': [],\n",
        "#     'cols_over_50_missing': ['B'],\n",
        "#     'duplicate_rows': [],\n",
        "#     'highly_correlated_pairs': [('C', 'D', 0.999)]\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_dataframe(df):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, None, 4, 5],\n",
        "    'B': [None, None, None, None, 5],\n",
        "    'C': [1, 2, 3, 4, 5],\n",
        "    'D': [1.1, 2.1, 3.1, 4.1, 5.1]\n",
        "})\n",
        "\n",
        "analysis = analyze_dataframe(df)\n",
        "print(\"DataFrame Analysis:\")\n",
        "for key, value in analysis.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section G: Data Selection & Filtering (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 31: Multi-Column Selector üü¢\n",
        "\n",
        "**Topic**: Column selection techniques\n",
        "\n",
        "**Description**:\n",
        "Select columns from DataFrame based on different criteria:\n",
        "- By data type (numeric, object, datetime)\n",
        "- By name pattern (contains, starts with, ends with)\n",
        "- By value threshold (mean > threshold)\n",
        "- Return new DataFrame with selected columns\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, 35],\n",
        "    'name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'salary': [50000, 60000, 70000],\n",
        "    'bonus': [5000, 6000, 7000]\n",
        "})\n",
        "\n",
        "select_columns(df, method='numeric')\n",
        "# Returns: DataFrame with ['age', 'salary', 'bonus']\n",
        "\n",
        "select_columns(df, method='contains', pattern='sal')\n",
        "# Returns: DataFrame with ['salary']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def select_columns(df, method='all', pattern=None, dtype=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, 35],\n",
        "    'name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'salary': [50000, 60000, 70000],\n",
        "    'bonus': [5000, 6000, 7000]\n",
        "})\n",
        "\n",
        "print(\"Numeric columns:\")\n",
        "print(select_columns(df, method='numeric'))\n",
        "\n",
        "print(\"\\nColumns containing 'sal':\")\n",
        "print(select_columns(df, method='contains', pattern='sal'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 32: Advanced Row Filtering üü°\n",
        "\n",
        "**Topic**: Complex boolean indexing\n",
        "\n",
        "**Description**:\n",
        "Filter DataFrame rows using multiple conditions:\n",
        "- Single condition (column > value)\n",
        "- AND condition (col1 > val1 AND col2 < val2)\n",
        "- OR condition (col1 > val1 OR col2 > val2)\n",
        "- BETWEEN condition (val1 < col < val2)\n",
        "- IN condition (col.isin([list]))\n",
        "- String matching (col.str.contains())\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'age': [25, 30, 35, 40],\n",
        "    'city': ['NYC', 'LA', 'NYC', 'Chicago'],\n",
        "    'salary': [50000, 60000, 70000, 80000]\n",
        "})\n",
        "\n",
        "filter_rows(df, conditions={'age': ('>', 30), 'city': ('==', 'NYC')}, logic='AND')\n",
        "# Returns rows where age > 30 AND city == 'NYC'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def filter_rows(df, conditions, logic='AND'):\n",
        "    # Write your code here\n",
        "    # conditions format: {'column': ('operator', value)}\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'age': [25, 30, 35, 40],\n",
        "    'city': ['NYC', 'LA', 'NYC', 'Chicago'],\n",
        "    'salary': [50000, 60000, 70000, 80000]\n",
        "})\n",
        "\n",
        "print(\"Age > 30:\")\n",
        "print(filter_rows(df, {'age': ('>', 30)}, logic='AND'))\n",
        "\n",
        "print(\"\\nAge > 30 AND city == NYC:\")\n",
        "print(filter_rows(df, {'age': ('>', 30), 'city': ('==', 'NYC')}, logic='AND'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 33: Loc vs iLoc Master üü°\n",
        "\n",
        "**Topic**: Label-based and position-based indexing\n",
        "\n",
        "**Description**:\n",
        "Practice both .loc and .iloc for various selection tasks:\n",
        "1. Select specific rows and columns by label\n",
        "2. Select specific rows and columns by position\n",
        "3. Select rows based on condition and specific columns\n",
        "4. Select every nth row\n",
        "5. Select last 3 rows and first 2 columns\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50],\n",
        "    'C': [100, 200, 300, 400, 500]\n",
        "}, index=['row1', 'row2', 'row3', 'row4', 'row5'])\n",
        "\n",
        "# Using .loc\n",
        "select_data(df, method='loc', rows=['row1', 'row3'], cols=['A', 'C'])\n",
        "# Returns:\n",
        "#       A    C\n",
        "# row1  1  100\n",
        "# row3  3  300\n",
        "\n",
        "# Using .iloc\n",
        "select_data(df, method='iloc', rows=[0, 2], cols=[0, 2])\n",
        "# Same result but using positions\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def select_data(df, method='loc', rows=None, cols=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50],\n",
        "    'C': [100, 200, 300, 400, 500]\n",
        "}, index=['row1', 'row2', 'row3', 'row4', 'row5'])\n",
        "\n",
        "print(\"Using .loc:\")\n",
        "print(select_data(df, method='loc', rows=['row1', 'row3'], cols=['A', 'C']))\n",
        "\n",
        "print(\"\\nUsing .iloc:\")\n",
        "print(select_data(df, method='iloc', rows=[0, 2], cols=[0, 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 34: Query Method Expert üü°\n",
        "\n",
        "**Topic**: DataFrame.query() for readable filtering\n",
        "\n",
        "**Description**:\n",
        "Use the .query() method to filter DataFrames with string expressions:\n",
        "- Simple comparisons\n",
        "- Multiple conditions with 'and', 'or'\n",
        "- Use of external variables with @\n",
        "- String column operations\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'salary': [50000, 60000, 70000, 80000, 90000],\n",
        "    'department': ['IT', 'HR', 'IT', 'Sales', 'IT']\n",
        "})\n",
        "\n",
        "threshold = 65000\n",
        "\n",
        "filter_with_query(df, \"age > 30 and salary > @threshold\")\n",
        "# Returns rows where age > 30 and salary > 65000\n",
        "\n",
        "filter_with_query(df, \"department == 'IT'\")\n",
        "# Returns all IT department rows\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def filter_with_query(df, query_string):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40, 45],\n",
        "    'salary': [50000, 60000, 70000, 80000, 90000],\n",
        "    'department': ['IT', 'HR', 'IT', 'Sales', 'IT']\n",
        "})\n",
        "\n",
        "threshold = 65000\n",
        "\n",
        "print(\"Age > 30 and salary > threshold:\")\n",
        "print(filter_with_query(df, \"age > 30 and salary > @threshold\"))\n",
        "\n",
        "print(\"\\nDepartment == 'IT':\")\n",
        "print(filter_with_query(df, \"department == 'IT'\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 35: Top N Selector üî¥\n",
        "\n",
        "**Topic**: nlargest, nsmallest, and ranking\n",
        "\n",
        "**Description**:\n",
        "Create a function that finds top/bottom N rows based on multiple criteria:\n",
        "- Top N by single column\n",
        "- Top N by multiple columns (with priority)\n",
        "- Bottom N with ties handling\n",
        "- Percentage-based selection (top 20%)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'score': [85, 92, 88, 92, 78],\n",
        "    'time': [120, 100, 110, 95, 130]\n",
        "})\n",
        "\n",
        "select_top_n(df, n=2, column='score', method='largest')\n",
        "# Returns:\n",
        "#      name  score  time\n",
        "# 1     Bob     92   100\n",
        "# 3   David     92    95\n",
        "\n",
        "select_top_n(df, n=2, columns=['score', 'time'], method='largest', priority='score')\n",
        "# First sort by score (desc), then by time (desc)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def select_top_n(df, n=5, column=None, columns=None, method='largest', keep='all'):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'score': [85, 92, 88, 92, 78],\n",
        "    'time': [120, 100, 110, 95, 130]\n",
        "})\n",
        "\n",
        "print(\"Top 2 by score:\")\n",
        "print(select_top_n(df, n=2, column='score', method='largest'))\n",
        "\n",
        "print(\"\\nBottom 2 by time:\")\n",
        "print(select_top_n(df, n=2, column='time', method='smallest'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section G: GroupBy & Aggregation (5 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 36: Basic GroupBy Aggregation üü¢\n",
        "\n",
        "**Topic**: Single column groupby with simple aggregations\n",
        "\n",
        "**Description**:\n",
        "Group data by a column and apply aggregations:\n",
        "- Sum, mean, median, count, std, min, max\n",
        "- Custom aggregation functions\n",
        "- Return dictionary with aggregation results\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'category': ['A', 'B', 'A', 'B', 'A', 'C'],\n",
        "    'value': [10, 20, 30, 40, 50, 60],\n",
        "    'count': [1, 2, 3, 4, 5, 6]\n",
        "})\n",
        "\n",
        "group_and_aggregate(df, groupby='category', agg_col='value', agg_func='mean')\n",
        "# Output:\n",
        "# {\n",
        "#     'A': 30.0,\n",
        "#     'B': 30.0,\n",
        "#     'C': 60.0\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def group_and_aggregate(df, groupby, agg_col, agg_func='mean'):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'category': ['A', 'B', 'A', 'B', 'A', 'C'],\n",
        "    'value': [10, 20, 30, 40, 50, 60],\n",
        "    'count': [1, 2, 3, 4, 5, 6]\n",
        "})\n",
        "\n",
        "print(\"Mean by category:\")\n",
        "print(group_and_aggregate(df, groupby='category', agg_col='value', agg_func='mean'))\n",
        "\n",
        "print(\"\\nSum by category:\")\n",
        "print(group_and_aggregate(df, groupby='category', agg_col='value', agg_func='sum'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 37: Multiple Aggregations üü°\n",
        "\n",
        "**Topic**: Apply multiple aggregation functions at once\n",
        "\n",
        "**Description**:\n",
        "Group by column and apply multiple aggregations to different columns:\n",
        "- Use .agg() with dictionary\n",
        "- Named aggregations\n",
        "- Return DataFrame with multi-level columns\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'department': ['IT', 'HR', 'IT', 'HR', 'Sales'],\n",
        "    'employee': ['A', 'B', 'C', 'D', 'E'],\n",
        "    'salary': [50000, 45000, 55000, 48000, 52000],\n",
        "    'experience': [5, 3, 7, 4, 6]\n",
        "})\n",
        "\n",
        "multi_agg(df, groupby='department')\n",
        "# Returns DataFrame with:\n",
        "#            salary              experience\n",
        "#              mean  max  min      mean  max\n",
        "# department                                \n",
        "# HR          46500  48000  45000  3.5    4\n",
        "# IT          52500  55000  50000  6.0    7\n",
        "# Sales       52000  52000  52000  6.0    6\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def multi_agg(df, groupby):\n",
        "    # Write your code here\n",
        "    # Apply multiple aggregations\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'department': ['IT', 'HR', 'IT', 'HR', 'Sales'],\n",
        "    'employee': ['A', 'B', 'C', 'D', 'E'],\n",
        "    'salary': [50000, 45000, 55000, 48000, 52000],\n",
        "    'experience': [5, 3, 7, 4, 6]\n",
        "})\n",
        "\n",
        "result = multi_agg(df, groupby='department')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 38: Transform and Apply üü°\n",
        "\n",
        "**Topic**: GroupBy transform and apply methods\n",
        "\n",
        "**Description**:\n",
        "Use transform and apply for group-wise operations:\n",
        "- Transform: Normalize values within each group (subtract group mean, divide by group std)\n",
        "- Apply: Custom function to each group\n",
        "- Return transformed DataFrame\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "    'value': [10, 20, 30, 40, 50, 60]\n",
        "})\n",
        "\n",
        "# Normalize within groups\n",
        "group_normalize(df, groupby='group', column='value')\n",
        "# Returns DataFrame with normalized values:\n",
        "#   group  value  normalized\n",
        "# 0     A     10       -1.0\n",
        "# 1     A     20        1.0\n",
        "# 2     B     30       -1.0\n",
        "# 3     B     40        1.0\n",
        "# 4     C     50       -1.0\n",
        "# 5     C     60        1.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def group_normalize(df, groupby, column):\n",
        "    # Write your code here\n",
        "    # Use transform to normalize within groups\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "    'value': [10, 20, 30, 40, 50, 60]\n",
        "})\n",
        "\n",
        "result = group_normalize(df, groupby='group', column='value')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 39: Pivot Table Creator üü°\n",
        "\n",
        "**Topic**: Pivot tables and cross-tabulation\n",
        "\n",
        "**Description**:\n",
        "Create pivot tables from DataFrames:\n",
        "- Simple pivot with one index and one column\n",
        "- Multiple aggregations\n",
        "- Add margins (totals)\n",
        "- Fill missing values\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'date': ['2024-01', '2024-01', '2024-02', '2024-02'],\n",
        "    'product': ['A', 'B', 'A', 'B'],\n",
        "    'sales': [100, 150, 120, 180],\n",
        "    'quantity': [10, 15, 12, 18]\n",
        "})\n",
        "\n",
        "create_pivot(df, index='date', columns='product', values='sales')\n",
        "# Returns:\n",
        "# product     A      B\n",
        "# date               \n",
        "# 2024-01   100    150\n",
        "# 2024-02   120    180\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def create_pivot(df, index, columns, values, aggfunc='sum', fill_value=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'date': ['2024-01', '2024-01', '2024-02', '2024-02'],\n",
        "    'product': ['A', 'B', 'A', 'B'],\n",
        "    'sales': [100, 150, 120, 180],\n",
        "    'quantity': [10, 15, 12, 18]\n",
        "})\n",
        "\n",
        "print(\"Pivot table:\")\n",
        "print(create_pivot(df, index='date', columns='product', values='sales'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 40: Advanced GroupBy with Filtering üî¥\n",
        "\n",
        "**Topic**: Complex groupby operations with filtering\n",
        "\n",
        "**Description**:\n",
        "Perform advanced groupby operations:\n",
        "- Filter groups based on group properties (size, sum, etc.)\n",
        "- Rank within groups\n",
        "- Calculate percentages within groups\n",
        "- Find top N within each group\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'store': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n",
        "    'product': ['X', 'Y', 'Z', 'X', 'Y', 'X', 'Y', 'Z', 'W'],\n",
        "    'sales': [100, 150, 200, 120, 180, 90, 110, 130, 140]\n",
        "})\n",
        "\n",
        "advanced_groupby(df, groupby='store', operations={\n",
        "    'filter_size': 3,  # Keep only groups with 3+ items\n",
        "    'top_n': 2,  # Top 2 products per store\n",
        "    'rank': True,  # Add rank within group\n",
        "    'pct': True  # Add percentage of total within group\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def advanced_groupby(df, groupby, operations):\n",
        "    # Write your code here\n",
        "    # Implement filter, rank, top N, percentages\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'store': ['A', 'A', 'A', 'B', 'B', 'C', 'C', 'C', 'C'],\n",
        "    'product': ['X', 'Y', 'Z', 'X', 'Y', 'X', 'Y', 'Z', 'W'],\n",
        "    'sales': [100, 150, 200, 120, 180, 90, 110, 130, 140]\n",
        "})\n",
        "\n",
        "operations = {'filter_size': 3, 'top_n': 2, 'rank': True}\n",
        "result = advanced_groupby(df, groupby='store', operations=operations)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Pandas Advanced Operations (10 Problems)\n",
        "\n",
        "## Section I: Missing Data (3 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 41: Missing Data Detector üü¢\n",
        "\n",
        "**Topic**: Identifying missing values\n",
        "\n",
        "**Description**:\n",
        "Create comprehensive missing data analysis:\n",
        "- Count missing values per column\n",
        "- Percentage of missing values\n",
        "- Identify patterns (missing in pairs, etc.)\n",
        "- Visualize missing data (text-based representation)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, None, 4, 5],\n",
        "    'B': [None, 2, 3, None, 5],\n",
        "    'C': [1, 2, 3, 4, 5]\n",
        "})\n",
        "\n",
        "analyze_missing(df)\n",
        "# Output: {\n",
        "#     'total_missing': 3,\n",
        "#     'by_column': {'A': 1, 'B': 2, 'C': 0},\n",
        "#     'percentage': {'A': 20.0, 'B': 40.0, 'C': 0.0},\n",
        "#     'rows_with_missing': [0, 2, 3],\n",
        "#     'complete_rows': 2\n",
        "# }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_missing(df):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, None, 4, 5],\n",
        "    'B': [None, 2, 3, None, 5],\n",
        "    'C': [1, 2, 3, 4, 5]\n",
        "})\n",
        "\n",
        "result = analyze_missing(df)\n",
        "print(\"Missing Data Analysis:\")\n",
        "for key, value in result.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 42: Smart Missing Value Imputer üü°\n",
        "\n",
        "**Topic**: Filling missing values with different strategies\n",
        "\n",
        "**Description**:\n",
        "Implement multiple imputation strategies:\n",
        "- Fill with mean/median/mode\n",
        "- Forward fill (ffill) / Backward fill (bfill)\n",
        "- Interpolate (linear, polynomial)\n",
        "- Fill with group mean (groupby then fill)\n",
        "- Fill with predictive model (simple linear regression)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'group': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
        "    'value': [10, None, 30, 40, None, 60]\n",
        "})\n",
        "\n",
        "impute_missing(df, column='value', method='mean')\n",
        "# Fills with overall mean: 35\n",
        "\n",
        "impute_missing(df, column='value', method='group_mean', groupby='group')\n",
        "# Fills with group mean: A=20, B=50\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def impute_missing(df, column, method='mean', groupby=None):\n",
        "    # Write your code here\n",
        "    # Implement different imputation strategies\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'group': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
        "    'value': [10.0, None, 30.0, 40.0, None, 60.0]\n",
        "})\n",
        "\n",
        "print(\"Original:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nImpute with mean:\")\n",
        "print(impute_missing(df, column='value', method='mean'))\n",
        "\n",
        "print(\"\\nImpute with group mean:\")\n",
        "print(impute_missing(df, column='value', method='group_mean', groupby='group'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 43: Missing Data Dropper üü°\n",
        "\n",
        "**Topic**: Removing rows/columns with missing values\n",
        "\n",
        "**Description**:\n",
        "Implement smart dropping strategies:\n",
        "- Drop rows with any missing values\n",
        "- Drop rows with all missing values\n",
        "- Drop rows with > threshold% missing\n",
        "- Drop columns with > threshold% missing\n",
        "- Keep only rows with at least N non-null values\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, None, None, 4],\n",
        "    'B': [None, None, None, None],\n",
        "    'C': [1, 2, 3, 4],\n",
        "    'D': [1, 2, None, 4]\n",
        "})\n",
        "\n",
        "drop_missing(df, axis=0, how='any', thresh=None)\n",
        "# Drops rows [0, 1, 2] (have any missing)\n",
        "\n",
        "drop_missing(df, axis=1, how='all')\n",
        "# Drops column B (all missing)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def drop_missing(df, axis=0, how='any', thresh=None, subset=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, None, None, 4],\n",
        "    'B': [None, None, None, None],\n",
        "    'C': [1, 2, 3, 4],\n",
        "    'D': [1, 2, None, 4]\n",
        "})\n",
        "\n",
        "print(\"Original:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\\nDrop rows with any missing:\")\n",
        "print(drop_missing(df, axis=0, how='any'))\n",
        "\n",
        "print(\"\\nDrop columns with all missing:\")\n",
        "print(drop_missing(df, axis=1, how='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section J: Merge & Join (4 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 44: Basic Merge Operations üü¢\n",
        "\n",
        "**Topic**: pd.merge() with different join types\n",
        "\n",
        "**Description**:\n",
        "Implement all four join types:\n",
        "- Inner join (intersection)\n",
        "- Left join (all from left)\n",
        "- Right join (all from right)\n",
        "- Outer join (union)\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df1 = pd.DataFrame({\n",
        "    'key': ['A', 'B', 'C'],\n",
        "    'value1': [1, 2, 3]\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'key': ['B', 'C', 'D'],\n",
        "    'value2': [4, 5, 6]\n",
        "})\n",
        "\n",
        "merge_dataframes(df1, df2, on='key', how='inner')\n",
        "# Returns:\n",
        "#   key  value1  value2\n",
        "# 0   B       2       4\n",
        "# 1   C       3       5\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def merge_dataframes(df1, df2, on=None, how='inner', left_on=None, right_on=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df1 = pd.DataFrame({\n",
        "    'key': ['A', 'B', 'C'],\n",
        "    'value1': [1, 2, 3]\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'key': ['B', 'C', 'D'],\n",
        "    'value2': [4, 5, 6]\n",
        "})\n",
        "\n",
        "print(\"Inner join:\")\n",
        "print(merge_dataframes(df1, df2, on='key', how='inner'))\n",
        "\n",
        "print(\"\\nLeft join:\")\n",
        "print(merge_dataframes(df1, df2, on='key', how='left'))\n",
        "\n",
        "print(\"\\nOuter join:\")\n",
        "print(merge_dataframes(df1, df2, on='key', how='outer'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 45: Concat and Join üü°\n",
        "\n",
        "**Topic**: pd.concat() and DataFrame.join()\n",
        "\n",
        "**Description**:\n",
        "Concatenate DataFrames vertically and horizontally:\n",
        "- Vertical concatenation (stacking rows)\n",
        "- Horizontal concatenation (adding columns)\n",
        "- Join on index\n",
        "- Handle mismatched indices\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
        "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
        "\n",
        "concat_vertical(df1, df2)\n",
        "# Returns:\n",
        "#    A  B\n",
        "# 0  1  3\n",
        "# 1  2  4\n",
        "# 0  5  7\n",
        "# 1  6  8\n",
        "\n",
        "concat_horizontal(df1, df2)\n",
        "# Returns:\n",
        "#    A  B  A  B\n",
        "# 0  1  3  5  7\n",
        "# 1  2  4  6  8\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def concat_dataframes(df1, df2, axis=0, ignore_index=False):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
        "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
        "\n",
        "print(\"Vertical concatenation:\")\n",
        "print(concat_dataframes(df1, df2, axis=0))\n",
        "\n",
        "print(\"\\nHorizontal concatenation:\")\n",
        "print(concat_dataframes(df1, df2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 46: Merge with Indicators üü°\n",
        "\n",
        "**Topic**: Advanced merge operations\n",
        "\n",
        "**Description**:\n",
        "Merge with indicator column to track source:\n",
        "- Add _merge column\n",
        "- Identify which rows came from left_only, right_only, or both\n",
        "- Handle suffixes for overlapping columns\n",
        "- Validate merge results\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df1 = pd.DataFrame({\n",
        "    'id': [1, 2, 3, 4],\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David']\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'id': [2, 3, 4, 5],\n",
        "    'score': [85, 90, 78, 92]\n",
        "})\n",
        "\n",
        "merge_with_indicator(df1, df2, on='id')\n",
        "# Returns DataFrame with _merge column showing:\n",
        "# 'left_only', 'right_only', or 'both'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def merge_with_indicator(df1, df2, on, how='outer'):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df1 = pd.DataFrame({\n",
        "    'id': [1, 2, 3, 4],\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David']\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'id': [2, 3, 4, 5],\n",
        "    'score': [85, 90, 78, 92]\n",
        "})\n",
        "\n",
        "result = merge_with_indicator(df1, df2, on='id')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 47: Multi-Key Merge üî¥\n",
        "\n",
        "**Topic**: Merging on multiple columns\n",
        "\n",
        "**Description**:\n",
        "Merge DataFrames on multiple keys:\n",
        "- Merge on 2+ columns\n",
        "- Handle composite keys\n",
        "- Different key names in each DataFrame\n",
        "- Validate merge integrity\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "sales = pd.DataFrame({\n",
        "    'year': [2023, 2023, 2024, 2024],\n",
        "    'quarter': ['Q1', 'Q2', 'Q1', 'Q2'],\n",
        "    'product': ['A', 'A', 'A', 'A'],\n",
        "    'revenue': [100, 150, 120, 180]\n",
        "})\n",
        "\n",
        "targets = pd.DataFrame({\n",
        "    'year': [2023, 2023, 2024, 2024],\n",
        "    'quarter': ['Q1', 'Q2', 'Q1', 'Q2'],\n",
        "    'target': [90, 140, 110, 170]\n",
        "})\n",
        "\n",
        "merge_multi_key(sales, targets, on=['year', 'quarter', 'product'])\n",
        "# Merges on all three keys\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def merge_multi_key(df1, df2, on=None, how='inner', validate=None):\n",
        "    # Write your code here\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "sales = pd.DataFrame({\n",
        "    'year': [2023, 2023, 2024, 2024],\n",
        "    'quarter': ['Q1', 'Q2', 'Q1', 'Q2'],\n",
        "    'product': ['A', 'A', 'A', 'A'],\n",
        "    'revenue': [100, 150, 120, 180]\n",
        "})\n",
        "\n",
        "targets = pd.DataFrame({\n",
        "    'year': [2023, 2023, 2024, 2024],\n",
        "    'quarter': ['Q1', 'Q2', 'Q1', 'Q2'],\n",
        "    'target': [90, 140, 110, 170]\n",
        "})\n",
        "\n",
        "result = merge_multi_key(sales, targets, on=['year', 'quarter'])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section K: Advanced Transformations (3 Problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 48: String Operations üü°\n",
        "\n",
        "**Topic**: String methods in pandas\n",
        "\n",
        "**Description**:\n",
        "Perform various string operations on DataFrame columns:\n",
        "- Extract patterns (regex)\n",
        "- Split strings into multiple columns\n",
        "- Clean whitespace\n",
        "- Change case\n",
        "- Replace patterns\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'email': ['alice@gmail.com', 'bob@yahoo.com', 'charlie@gmail.com'],\n",
        "    'phone': ['123-456-7890', '234-567-8901', '345-678-9012']\n",
        "})\n",
        "\n",
        "string_operations(df, column='email', operation='extract_domain')\n",
        "# Returns: ['gmail.com', 'yahoo.com', 'gmail.com']\n",
        "\n",
        "string_operations(df, column='phone', operation='remove_hyphens')\n",
        "# Returns: ['1234567890', '2345678901', '3456789012']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def string_operations(df, column, operation, pattern=None):\n",
        "    # Write your code here\n",
        "    # Implement different string operations\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'email': ['alice@gmail.com', 'bob@yahoo.com', 'charlie@gmail.com'],\n",
        "    'phone': ['123-456-7890', '234-567-8901', '345-678-9012']\n",
        "})\n",
        "\n",
        "print(\"Extract domain from email:\")\n",
        "print(string_operations(df, column='email', operation='extract_domain'))\n",
        "\n",
        "print(\"\\nRemove hyphens from phone:\")\n",
        "print(string_operations(df, column='phone', operation='remove_hyphens'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 49: DateTime Operations üî¥\n",
        "\n",
        "**Topic**: Working with dates and times\n",
        "\n",
        "**Description**:\n",
        "Perform datetime operations:\n",
        "- Parse strings to datetime\n",
        "- Extract components (year, month, day, hour)\n",
        "- Calculate date differences\n",
        "- Resample time series\n",
        "- Create date ranges\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'date': ['2024-01-01', '2024-01-15', '2024-02-01'],\n",
        "    'value': [100, 150, 200]\n",
        "})\n",
        "\n",
        "datetime_ops(df, column='date', operation='extract_month')\n",
        "# Returns: [1, 1, 2]\n",
        "\n",
        "datetime_ops(df, column='date', operation='days_since_first')\n",
        "# Returns: [0, 14, 31]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "\n",
        "def datetime_ops(df, column, operation):\n",
        "    # Write your code here\n",
        "    # Convert to datetime and perform operations\n",
        "    pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'date': ['2024-01-01', '2024-01-15', '2024-02-01'],\n",
        "    'value': [100, 150, 200]\n",
        "})\n",
        "\n",
        "print(\"Extract month:\")\n",
        "print(datetime_ops(df, column='date', operation='extract_month'))\n",
        "\n",
        "print(\"\\nDays since first date:\")\n",
        "print(datetime_ops(df, column='date', operation='days_since_first'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem 50: ML Feature Engineering Pipeline üî¥\n",
        "\n",
        "**Topic**: Complete data preprocessing pipeline\n",
        "\n",
        "**Description**:\n",
        "Create a comprehensive feature engineering pipeline:\n",
        "1. Handle missing values\n",
        "2. Encode categorical variables\n",
        "3. Scale numerical features\n",
        "4. Create interaction features\n",
        "5. Remove outliers\n",
        "6. Split into train/test sets\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, None, 40, 100],  # Has missing and outlier\n",
        "    'income': [50000, 60000, 70000, 80000, 90000],\n",
        "    'category': ['A', 'B', 'A', 'C', 'B'],  # Categorical\n",
        "    'target': [0, 1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "pipeline = FeatureEngineeringPipeline()\n",
        "X_train, X_test, y_train, y_test = pipeline.fit_transform(\n",
        "    df, \n",
        "    target_col='target',\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# Returns:\n",
        "# - Cleaned data\n",
        "# - Encoded categories\n",
        "# - Scaled features\n",
        "# - Train/test split\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class FeatureEngineeringPipeline:\n",
        "    def __init__(self):\n",
        "        self.encoders = {}\n",
        "        self.scalers = {}\n",
        "        pass\n",
        "    \n",
        "    def fit_transform(self, df, target_col, test_size=0.2):\n",
        "        # Write your complete pipeline here\n",
        "        # 1. Handle missing values\n",
        "        # 2. Encode categorical variables\n",
        "        # 3. Scale numerical features\n",
        "        # 4. Create interaction features\n",
        "        # 5. Remove outliers\n",
        "        # 6. Split into train/test\n",
        "        pass\n",
        "\n",
        "# Test your solution\n",
        "df = pd.DataFrame({\n",
        "    'age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
        "    'income': [50000, 60000, 70000, 80000, 90000, 55000, 65000, 75000, 85000, 95000],\n",
        "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
        "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "pipeline = FeatureEngineeringPipeline()\n",
        "X_train, X_test, y_train, y_test = pipeline.fit_transform(df, target_col='target', test_size=0.2)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéâ Congratulations! You've Completed All 50 Homework Assignments!\n",
        "\n",
        "## Summary:\n",
        "\n",
        "### Part 1: Python Data Structures (15 problems)\n",
        "‚úÖ **Tuples** (5 problems) - üü¢üü¢üü°üü°üî¥  \n",
        "‚úÖ **Sets** (5 problems) - üü¢üü°üü°üü°üî¥  \n",
        "‚úÖ **Dictionaries** (5 problems) - üü¢üü°üü°üî¥üî¥  \n",
        "\n",
        "### Part 2: Python Functions & Functional Programming (10 problems)\n",
        "‚úÖ **Functions & Decorators** (5 problems) - üü°üî¥üü°üî¥üî¥  \n",
        "‚úÖ **Functional Programming** (5 problems) - üü¢üü°üü°üî¥üî¥  \n",
        "\n",
        "### Part 3: Pandas Basics & Data Manipulation (15 problems)\n",
        "‚úÖ **Series & DataFrames** (5 problems) - üü¢üü¢üü°üü°üî¥  \n",
        "‚úÖ **Data Selection & Filtering** (5 problems) - üü¢üü°üü°üü°üî¥  \n",
        "‚úÖ **GroupBy & Aggregation** (5 problems) - üü¢üü°üü°üü°üî¥  \n",
        "\n",
        "### Part 4: Pandas Advanced Operations (10 problems)\n",
        "‚úÖ **Missing Data** (3 problems) - üü¢üü°üü°  \n",
        "‚úÖ **Merge & Join** (4 problems) - üü¢üü°üü°üî¥  \n",
        "‚úÖ **Advanced Transformations** (3 problems) - üü°üî¥üî¥  \n",
        "\n",
        "---\n",
        "\n",
        "## üìä Difficulty Breakdown:\n",
        "- üü¢ **Easy**: 10 problems (20%)\n",
        "- üü° **Medium**: 25 problems (50%)\n",
        "- üî¥ **Hard**: 15 problems (30%)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Skills Acquired:\n",
        "\n",
        "### Python Fundamentals:\n",
        "- Advanced data structures (tuples, sets, dictionaries)\n",
        "- Functions, decorators, and closures\n",
        "- Functional programming (map, filter, reduce, lambda)\n",
        "- List/dict/set comprehensions\n",
        "- Higher-order functions and composition\n",
        "\n",
        "### Pandas Mastery:\n",
        "- Series and DataFrame creation and manipulation\n",
        "- Data selection, filtering, and indexing\n",
        "- GroupBy operations and aggregations\n",
        "- Pivot tables and cross-tabulation\n",
        "- Missing data handling strategies\n",
        "- Merging, joining, and concatenating datasets\n",
        "- String and datetime operations\n",
        "- Feature engineering pipelines\n",
        "\n",
        "### Machine Learning Applications:\n",
        "- Data preprocessing and cleaning\n",
        "- Feature engineering and encoding\n",
        "- Train/test splitting\n",
        "- Outlier detection and removal\n",
        "- Data normalization and scaling\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Next Steps:\n",
        "\n",
        "1. **Practice More**: Solve these problems again without looking at solutions\n",
        "2. **Real Datasets**: Apply concepts to Kaggle datasets\n",
        "3. **Projects**: Build end-to-end data science projects\n",
        "4. **Advanced Topics**: \n",
        "   - scikit-learn for ML models\n",
        "   - matplotlib/seaborn for visualization\n",
        "   - SQL integration with pandas\n",
        "   - Big data with Dask/PySpark\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Recommended Practice:\n",
        "\n",
        "- **Kaggle**: Participate in competitions\n",
        "- **LeetCode**: SQL and Python challenges\n",
        "- **HackerRank**: Data structure challenges\n",
        "- **Real World**: Personal data analysis projects\n",
        "\n",
        "---\n",
        "\n",
        "**Keep coding and happy learning! üéìüíª**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
